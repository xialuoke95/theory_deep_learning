{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some points\n",
    "keras inputs shape 里是不含 batch_size 的\n",
    "tf 基础框架，张量需要严格对齐，model.fit 则会做一些自定义的方便处理，比如 y_label 是 (None, 1) 或者 (None, )的输入都行\n",
    "reduction = 'sum' / 'sum_over_batch_size'，sum_over_batch_size 计算出的loss基本是每条样本平均的loss, 等价于 tf.reduce_mean\n",
    "    \n",
    "可复现结果：但如果是 BGD，一个batch去算，不应该有这个问题？确认一下BGD\n",
    "- np.set_random_seed 这些没用，keras_initializer有用\n",
    "\n",
    "with session() 的sess.run里也会改变变量赋值！要注意原始输入原始数据的隔离\n",
    "model.compile & sess.run(init) 承担了图及图内 可变tensor 的基本初始化，初始化之前是没有良定义的\n",
    "\n",
    "============================= 最小子集问题\n",
    "============================== 几个没解决的 api问题：\n",
    "1. tf.cast 容易丢失精度? sigmoid_cross_entropy 容易溢出? float32 vs float16, 进一步 int8 优化也可能带来相关风险\n",
    "\n",
    "2. 同名变量定义了2次，tf图里怎么处理？\n",
    "3. 可复现结果：\n",
    "    https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "    https://stackoverflow.com/questions/59075244/if-keras-results-are-not-reproducible-whats-the-best-practice-for-comparing-mo\n",
    "    目前发现同样的参数，只更新10条样本，新预测结果也会不同。或许 tf2.0 才比较好的解决了这个问题\n",
    "    train_on_batch 和 fit都无法解决这个问题\n",
    "    这是SGD算法带来的本质问题么？: https://github.com/keras-team/keras/issues/2743\n",
    "    \n",
    "\n",
    "4. fit vs train_on_batch:\n",
    "    - fit 并不会把weights清零; 这点上说和 train_on_batch 一样\n",
    "    - batch_size, epochs概念：默认情况下 batch_size = 32, epochs是所有数据被过的轮数\n",
    "    比如 96条数据 epochs=1, 则实际 iter =3；epochs=3，则实际 iter = 9.\n",
    "    steps_per_epoch: 可以控制数据并不全部过完，比如每个epoch只过1个iter，那就只过前32条 \n",
    "    - reset_states: LSTM的问题，https://stackoverflow.com/questions/43882796/when-does-keras-reset-an-lstm-stats\n",
    "    reset states after batch，train_on_batch 直接做到这一点。model.fit 则保存states, 除非显式指定一个序列已经结束。不确切知道在说啥\n",
    "\n",
    "=============================== 几个没解决的算法问题\n",
    "受限的值域范围: 看看影响有多大（mao_model） ---> 故意控制受限值域范围？\n",
    "已知有影响:同步异步，初始化 (46000 vs 38000)\n",
    "经过多轮不同起始点的迭代，参数weight是否其实区别很大，但仍然能比较好的刻画结果？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug\n",
    "\n",
    "1. from_logits should be True\n",
    "layers.Dense(activation='sigmoid') + from_logits=False: layers.Dense(activation=None) + from_logits=True. \n",
    "默认 from_logits=False\n",
    "    - 如果 activation = none + from_logits=False, 会影响效果\n",
    "    \n",
    "2. TF optimize Bug\n",
    "SGD vs all GD, batch_size & epoch 是一个平衡, 在iter一定的情况下，也许batch_size越大越好；但epoch一定的情况下，则不一定\n",
    "一个batch一个batch train很重要；train足够多次也能解决问题\n",
    "\n",
    "3. keras and tf api of predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a classify model to tell if a number is 1.\n",
    "# save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0, \"/Users/bytedance/LearningProjects/theory_deep_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH= '/Users/bytedance/LearningProjects/theory_deep_learning/generative_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from utils.plot_image import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "###  tf.random.set_seed(1234) --->\n",
    "tf.compat.v1.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-14563ddb1bf4>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/bytedance/miniconda3/envs/tf1/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/bytedance/miniconda3/envs/tf1/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/bytedance/LearningProjects/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bytedance/miniconda3/envs/tf1/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/bytedance/LearningProjects/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/bytedance/LearningProjects/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/bytedance/LearningProjects/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bytedance/miniconda3/envs/tf1/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/Users/bytedance/LearningProjects/MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mnist.train.images\n",
    "X.shape\n",
    "\n",
    "# X_new = tf.reshape(X, [-1, 28, 28])\n",
    "# with tf.Session() as sess:\n",
    "#     print sess.run(X_new[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label = (mnist.train.labels == 1).astype(float)\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.9841 - acc: 0.9906\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.4444 - acc: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ee39015d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bug: from_logits should be True\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337)),\n",
    "  tf.keras.layers.Dense(1, activation=None, kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction='sum'),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TF optimize Bug: model.fit(X, y_label, batch_size=50000, epochs=2)\n",
    "model.fit(X, y_label, epochs=2)\n",
    "# model.fit(X, y_label_for_tf, epochs=2) # 也是ok的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = '/Users/bytedance/LearningProjects/theory_deep_learning/generative_model/'\n",
    "model.save_weights(pwd + 'weights/weights_keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-13.515839 ]\n",
      " [-11.02475  ]\n",
      " [-13.867207 ]\n",
      " [-10.416041 ]\n",
      " [  6.316296 ]\n",
      " [-12.889773 ]\n",
      " [  6.7167487]\n",
      " [-20.945826 ]\n",
      " [ -9.196559 ]\n",
      " [-11.598768 ]]\n",
      "[0.0018535329, 1.0]\n",
      "============ [[-13.632476]\n",
      " [-11.158817]\n",
      " [-14.147933]\n",
      " [-10.686915]\n",
      " [  7.576985]\n",
      " [-12.935309]\n",
      " [  8.107263]\n",
      " [-21.094677]\n",
      " [ -9.358425]\n",
      " [-11.686738]]\n",
      "[0.0018535329, 1.0]\n",
      "============ [[-13.805994 ]\n",
      " [-11.368531 ]\n",
      " [-14.37539  ]\n",
      " [-10.927068 ]\n",
      " [  7.9972553]\n",
      " [-13.095317 ]\n",
      " [  8.5774145]\n",
      " [-21.313025 ]\n",
      " [ -9.50106  ]\n",
      " [-11.866906 ]]\n",
      "5/5 [==============================] - 0s 265us/sample - loss: 0.0019 - acc: 1.0000\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7f8ec2237b10>\n",
      "5/5 [==============================] - 0s 316us/sample - loss: 0.0019 - acc: 1.0000\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7f8ec2237fd0>\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(pwd + 'weights/weights_keras')\n",
    "print model.predict(X[0:10])\n",
    "\n",
    "for i in range(2):\n",
    "    model.load_weights(pwd + 'weights/weights_keras')\n",
    "    print model.train_on_batch(X[0:5], y_label[0:5])\n",
    "    print '============', model.predict(X[0:10])\n",
    "\n",
    "for i in range(2):\n",
    "    model.load_weights(pwd + 'weights/weights_keras')\n",
    "    print model.fit(X[0:5], y_label[0:5], epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.0299 - acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff1517c3510>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(\n",
    "      128, activation='relu', \n",
    "      kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337),\n",
    "      bias_initializer=tf.keras.initializers.Constant(value=0.1)\n",
    "  ),\n",
    "  tf.keras.layers.Dense(\n",
    "      1, activation=None, \n",
    "      kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337),\n",
    "      bias_initializer=tf.keras.initializers.Constant(value=0.1)\n",
    "  )\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y_label, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07627121]\n",
      " [-0.03569068]\n",
      " [ 0.08577306]\n",
      " [-0.26084673]\n",
      " [-0.05733486]\n",
      " [ 0.13431373]\n",
      " [ 0.06105527]\n",
      " [-0.16407387]\n",
      " [-0.01952023]\n",
      " [ 0.00732557]]\n",
      "loss 0.7065882\n",
      "=====================\n",
      "[[-0.07627121]\n",
      " [-0.03569068]\n",
      " [ 0.08577306]\n",
      " [-0.26084673]\n",
      " [-0.05733486]\n",
      " [ 0.13431373]\n",
      " [ 0.06105527]\n",
      " [-0.16407387]\n",
      " [-0.01952023]\n",
      " [ 0.00732557]]\n",
      "loss 0.7065882\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "#==================== INIT 初始化已经得到了很好的控制。但是训练结果仍然有微小的区别\n",
    "# Bug: keras and tf api of predict result: 把 model_v2.predict 放到 sess.run 模型图里就出问题\n",
    "for i in range(2):\n",
    "    model_v2 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337)),\n",
    "      tf.keras.layers.Dense(1, activation=None, kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337))\n",
    "    ])\n",
    "    print model_v2.predict(X[0:10])\n",
    "    \n",
    "    logits_ = model_v2.predict(X)\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits= logits_,\n",
    "            labels= tf.cast(np.expand_dims(y_label, axis=1), tf.float32)\n",
    "        ))\n",
    "        print 'loss', sess.run(loss)\n",
    "    print '====================='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f8ec1372390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#====================== 更改模型参数并重新load？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07627121]\n",
      " [-0.03569068]\n",
      " [ 0.08577306]\n",
      " [-0.26084673]\n",
      " [-0.05733486]\n",
      " [ 0.13431373]\n",
      " [ 0.06105527]\n",
      " [-0.16407387]\n",
      " [-0.01952023]\n",
      " [ 0.00732557]]\n",
      "[[-14.109363 ]\n",
      " [ -9.612924 ]\n",
      " [-12.866566 ]\n",
      " [ -9.374281 ]\n",
      " [  5.5253906]\n",
      " [-11.393759 ]\n",
      " [  6.166926 ]\n",
      " [-20.481354 ]\n",
      " [ -9.071522 ]\n",
      " [-10.516313 ]]\n"
     ]
    }
   ],
   "source": [
    "model_v2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337)),\n",
    "  tf.keras.layers.Dense(1, activation=None, kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337))\n",
    "])\n",
    "\n",
    "print model_v2.predict(X[0:10])\n",
    "model_v2.load_weights(pwd + 'weights/weights_keras')\n",
    "print model_v2.predict(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================= see model predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-14.109363 ],\n",
       "       [ -9.612924 ],\n",
       "       [-12.866566 ],\n",
       "       [ -9.374281 ],\n",
       "       [  5.5253906],\n",
       "       [-11.393759 ],\n",
       "       [  6.166926 ],\n",
       "       [-20.481354 ],\n",
       "       [ -9.071522 ],\n",
       "       [-10.516313 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple NN use tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "y:  [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print X[0:10]\n",
    "print 'y: ', y_label[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7065882\n",
      "[[-0.07627121]\n",
      " [-0.03569068]\n",
      " [ 0.08577306]\n",
      " [-0.26084673]\n",
      " [-0.05733486]\n",
      " [ 0.13431373]\n",
      " [ 0.06105527]\n",
      " [-0.16407387]\n",
      " [-0.01952023]\n",
      " [ 0.00732557]]\n",
      "loss 0.020643558\n",
      "logits [[-15.1961155]\n",
      " [ -9.166121 ]\n",
      " [-13.746687 ]\n",
      " [-10.323326 ]\n",
      " [  7.644575 ]\n",
      " [-11.415566 ]\n",
      " [  8.236807 ]\n",
      " [-20.396305 ]\n",
      " [ -9.598089 ]\n",
      " [-10.171268 ]]\n",
      "INFO:tensorflow:/Users/bytedance/LearningProjects/theory_deep_learning/generative_model/weights_tf/ is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# Bug: TF optimize Bug, batch_size = 50000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    batch_size = 32\n",
    "    epoch = 1\n",
    "    sample_total_num = X.shape[0]\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(784,), dtype=\"float32\")\n",
    "    labels = tf.keras.Input(shape=(), dtype=\"float32\")\n",
    "    layers = [\n",
    "        tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337)),\n",
    "        tf.keras.layers.Dense(1, activation=None, kernel_initializer=tf.keras.initializers.RandomNormal(seed=1337))\n",
    "    ]\n",
    "    x1 = layers[0](inputs)\n",
    "    logits = layers[1](x1)\n",
    "    \n",
    "    # logits = tf.reduce_sum(logits, axis=1)\n",
    "    # loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    \n",
    "    label_for_tf = tf.expand_dims(labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=label_for_tf))\n",
    "    \n",
    "    train_optim = tf.train.AdamOptimizer().minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print sess.run(loss, feed_dict={inputs: X, labels: y_label})\n",
    "    print sess.run(logits, feed_dict={inputs: X[0:10]})\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        start_idx = 0\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        while end_idx < sample_total_num:\n",
    "            x_batch = X[start_idx: end_idx]\n",
    "            y_batch = y_label[start_idx: end_idx]\n",
    "            sess.run(train_optim, feed_dict={inputs: x_batch, labels: y_batch})\n",
    "            \n",
    "            start_idx = end_idx\n",
    "            end_idx = start_idx + batch_size\n",
    "    \n",
    "    print 'loss', sess.run(loss, feed_dict={inputs: X, labels: y_label})\n",
    "    print 'logits', sess.run(logits, feed_dict={inputs: X[0:10]})\n",
    "    \n",
    "    pwd = '/Users/bytedance/LearningProjects/theory_deep_learning/generative_model/'\n",
    "    path = pwd + 'weights_tf/'\n",
    "    saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=None)\n",
    "    saver.save(sess, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================ for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_label_cast = tf.cast(y_label, tf.float32)\n",
    "    print sess.run(y_label_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.2345 - acc: 0.99760s - loss: 0.22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ee3adf0d0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_label, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
